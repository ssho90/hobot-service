MCP (모델 컨텍스트 프로토콜)이란 무엇이고 어떻게 작동하는가
모델 컨텍스트 프로토콜(MCP)에 대한 이해하기 쉬운 가이드로, LLM이 지식의 한계를 극복하고 더 강력한 AI 애플리케이션을 구축할 수 있도록 외부 리소스에 액세스하는 방법을 설명합니다.

Yijun
Yijun
Developer
3/4/2025

사용자 인증에 몇 주를 낭비하지 마세요
Logto로 더 빠르게 안전한 앱을 출시하세요. 몇 분 만에 사용자 인증을 통합하고 핵심 제품에 집중하세요.
Product screenshot
MCP란 무엇인가?#
MCP (모델 컨텍스트 프로토콜)은 애플리케이션이 대형 언어 모델(LLM)에 컨텍스트 정보를 제공하는 방식을 표준화하는 개방적이고 보편적인 프로토콜입니다.

간단히 말해, HTTP 프로토콜이 서로 다른 웹사이트와 브라우저가 동일한 규칙에 따라 정보를 교환할 수 있도록 하는 것처럼, MCP는 AI 세계의 HTTP 프로토콜과 같습니다. MCP는 다양한 AI 모델이 다양한 데이터 소스와 도구에 표준화된 방식으로 연결할 수 있게 합니다. 이러한 표준화는 개발자들이 각각의 모델이나 데이터 소스를 위한 특수한 인터페이스를 만들 필요 없이 AI 애플리케이션을 더 쉽게 구축할 수 있게 만듭니다.

MCP가 필요한 이유#
대형 언어 모델(LLM)은 강력하지만 몇 가지 주요 한계에 직면해 있습니다:

지식의 한계와 업데이트 문제: LLM은 훈련 데이터에 포함된 정보만 알고 있습니다. 예를 들어 GPT-4의 지식은 2023년 4월에 종료됩니다. 대형 언어 모델을 훈련하는 데는 엄청난 컴퓨팅 자원과 시간이 필요하며, 종종 새로운 버전을 완성하는 데 6개월 이상이 걸립니다. 이는 어려운 문제를 만듭니다: 모델 지식은 항상 "구식"이며, 업데이트는 비용이 많이 들고 시간 소모적입니다. 새로운 모델이 훈련을 마칠 때쯤에는 이미 지식이 뒤처지기 시작합니다.

전문 도메인 지식의 부족: LLM은 공개적으로 이용 가능한 일반 데이터를 사용하여 훈련됩니다. 이는 특정 비즈니스 시나리오에서 깊이 있는 데이터와 정보를 이해할 수 없다는 것을 의미합니다. 예를 들어, 의료 기관의 내부 프로세스, 회사의 제품 카탈로그 또는 조직의 독점적인 지식은 모델의 훈련 범위에 포함되지 않습니다.

외부 데이터에 액세스할 통일된 표준이 없음: 현재, LLM에 추가 정보를 제공하는 데 많은 방법들이 있으며, 예를 들어 RAG(검색 기반 생성), 로컬 지식 기반, 인터넷 검색 등. 다양한 개발팀이 다른 통합 솔루션을 제공함으로써 시스템 간 통합 비용이 높아집니다. CRM, ERP, 의료 기록 시스템과 같은 전문 도메인 데이터를 가진 시스템은 LLM과 매끄럽게 통합하기가 어렵습니다. 각 통합은 공통된 표준화된 방법 없이 사용자 정의 개발이 필요합니다.

이러한 이유로 우리는 MCP가 필요합니다. MCP는 LLM이 외부 정보와 도구에 일관된 방식으로 접근할 수 있게 하는 표준화된 프로토콜을 제공하여 위의 모든 문제를 해결합니다. MCP를 통해 다음과 같은 주요 이점을 얻을 수 있습니다:

풍부한 사전 구축 통합: MCP는 파일 시스템, 데이터베이스(PostgreSQL, SQLite), 개발 도구(Git, GitHub, GitLab), 네트워크 도구(Brave Search, Fetch), 생산성 도구(Slack, Google Maps) 등을 포함한 다수의 사전 제작된 서버 통합을 제공합니다. 이는 이러한 통합을 처음부터 구축할 필요가 없다는 것을 의미합니다. 이러한 사전 제작된 커넥터를 사용하여 LLM이 이러한 시스템에서 데이터를 액세스할 수 있도록 할 수 있습니다.

LLM 제공자 간의 유연한 전환: 오늘은 GPT-4를 사용하고 있다가, 내일은 Claude나 Gemini를 사용하거나, 다른 시나리오에 다른 LLM을 사용하고 싶을 수도 있습니다. MCP를 사용하면 전체 애플리케이션의 통합 로직을 다시 작성할 필요가 없습니다. 단지 하위 모델을 변경하면, 모든 데이터 및 도구 통합은 그대로 유지됩니다.

복잡한 AI 워크플로우 구축: 여러 데이터베이스를 쿼리하고 문서 비교를 위한 특정 도구를 사용하며 보고서를 생성해야 하는 법률 문서 분석 시스템을 상상해 보십시오. MCP는 LLM 위에 이러한 복잡한 에이전트와 워크플로우를 구축할 수 있게 합니다.

MCP는 어떻게 작동하나요#
MCP에는 세 가지 핵심 역할이 있습니다: MCP 서버(도구 및 데이터 액세스 제공), MCP 클라이언트(LLM에 포함되어 MCP 서버와 통신), 그리고 MCP 호스트(Claude Desktop, Cursor 등과 같은 LLM 및 클라이언트를 통합하는 애플리케이션). 이 세 가지 역할이 어떻게 협력하는지 자세히 살펴보겠습니다.

MCP 서버#
MCP 서버는 LLM이 사용할 수 있는 도구와 데이터 액세스 기능을 제공하는 프로그램입니다. 전통적인 원격 API 서버와는 달리, MCP 서버는 사용자의 장치에서 로컬 애플리케이션으로 실행되거나 원격 서버에 배포될 수 있습니다.

각 MCP 서버는 로컬 데이터나 원격 서비스에서 정보를 검색하는 특정 도구 세트를 제공합니다. LLM이 작업을 처리하는 동안 특정 도구를 사용해야 한다고 결정하면, MCP 서버가 제공하는 도구를 사용하여 필요한 데이터를 얻고 이를 LLM에 반환합니다.


MCP 클라이언트#
MCP 클라이언트는 LLM과 MCP 서버를 연결하는 브리지입니다. LLM에 포함되어 다음과 같은 역할을 담당합니다:

LLM으로부터 요청 수신
적절한 MCP 서버로 요청 전달
MCP 서버로부터 결과를 LLM에 반환

MCP 클라이언트 개발을 확인하여 LLM과 MCP 클라이언트를 통합하는 방법에 대해 자세히 알아볼 수 있습니다.

MCP 호스트#
Claude Desktop, IDE(Cursor 등), 또는 MCP를 통해 데이터를 액세스하고자 하는 AI 도구와 같은 프로그램. 이러한 애플리케이션은 사용자가 LLM과 상호작용할 수 있는 인터페이스를 제공하면서, MCP 클라이언트를 통합하여 MCP 서버가 제공하는 도구를 사용하여 LLM 기능을 확장합니다.


MCP 워크플로우#
위의 세 가지 역할이 결국 MCP를 기반으로 구축된 AI 애플리케이션을 형성합니다.


이 시스템의 예제 워크플로우는 다음과 같습니다:


MCP 서버 빌드 방법#
MCP 서버는 MCP 시스템에서 가장 중요한 링크입니다. 이는 LLM이 액세스할 수 있는 도구와 데이터를 결정하며, AI 애플리케이션의 기능적 경계와 역량에 직접적으로 영향을 미칩니다.

자신의 MCP 서버를 구축하려면 공식 MCP 퀵스타트 가이드를 먼저 읽는 것이 좋습니다. 환경 설정부터 MCP 서버 구현 및 사용에 이르기까지 전체 프로세스를 자세히 설명하고 있습니다. 우리는 핵심 구현 세부사항만 설명합니다.

MCP 서버가 제공하는 도구 정의#
MCP 서버의 핵심 기능은 server.tool() 메서드를 통해 도구를 정의하는 것입니다. 이러한 도구는 LLM이 외부 데이터를 얻거나 특정 작업을 수행하기 위해 호출할 수 있는 함수입니다. Node.js를 사용한 간단한 예제를 살펴보겠습니다:

// 회사 지식 기반에서 문서를 검색하는 도구 정의
server.tool(
  "search-documents",
  "Search for documents in the company knowledge base",
  {
    query: z.string().describe("Search keywords or question"),
    max_results: z.number().default(5).describe("Maximum number of results to return")
  },
  async ({ query, max_results }) => {
    // 실제 구현은 지식 기반 시스템에 연결될 것입니다
    // 간단한 예제 반환
    const results = [
      "Product Manual v2.1",
      "Frequently Asked Questions",
      "Technical Specifications"
    ].slice(0, max_results);
    
    const formattedResults = results.map((title, index) => 
      `${index + 1}. ${title}`
    ).join("\n");
    
    return {
      content: [
        {
          type: "text",
          text: `Results for '${query}':\n${formattedResults}`
        }
      ]
    };
  }
);
이 예제에서는 search-documents라는 도구를 정의하여 쿼리 문자열과 결과의 최대 개수를 매개변수로 받습니다. 도구의 구현은 지식 기반 시스템에 연결하여 쿼리 결과를 반환합니다.

LLM은 도구의 정의와 사용자의 질문에 따라 이 도구를 사용할지 결정합니다. 필요하다면, LLM은 이 도구를 호출하고 결과를 얻어 사용자의 질문과 결합하여 답변을 생성합니다.

도구 정의를 위한 모범 사례#
이러한 도구를 구축할 때 다음과 같은 모범 사례를 따를 수 있습니다:

명확한 설명: 각 도구에 대해 자세하고 정확한 설명을 제공하여 그 기능, 적용 가능한 시나리오, 제한 사항을 명확히 하십시오. 이는 LLM이 적절한 도구를 선택하는 데 도움이 될 뿐만 아니라 개발자가 코드를 이해하고 유지 보수하는 데도 용이합니다.

매개변수 검증: Zod 또는 유사한 라이브러리를 사용하여 입력 매개변수를 엄격히 검증하여 올바른 유형, 합리적인 값 범위를 보장하고 준수하지 않는 입력을 거부하십시오. 이는 백엔드 시스템으로 오류가 확산되는 것을 방지하고 전체 안정성을 향상시킵니다.

오류 처리: 포괄적인 오류 처리 전략을 구현하고 가능한 예외를 포착하여 사용자 친화적인 오류 메시지를 반환하십시오. 이는 사용자 경험을 향상시키며, LLM이 단순히 실패하는 대신 오류 조건에 기반한 의미 있는 응답을 제공할 수 있도록 합니다.

데이터 액세스 제어: 백엔드 리소스 API가 강력한 인증 및 권한 부여 메커니즘을 가지고 있으며, MCP 서버가 사용자가 권한을 가진 데이터만 액세스하고 반환하도록 권한 범위를 신중히 설계하십시오. 이는 민감한 정보 누출을 방지하고 데이터 보안을 보장합니다.

MCP(AI 모델)와 외부 시스템 간의 데이터 교환 보안 방법#
AI 모델과 외부 시스템을 연결하는 MCP 서버를 구현할 때, MCP 구현에서 두 가지 주요 보안 과제가 있습니다:

인증: 전통적인 애플리케이션과 달리, MCP 환경에서는 사용자가 외부 시스템에 접근하기 위해 전통적인 로그인 플로우(예: 사용자 이름/비밀번호, 이메일/인증 코드 등)를 통해 로그인할 수 없습니다.

MCP 서버 요청의 접근 제어: AI 도구를 통해 시스템에 접근하는 사용자는 동일한 시스템을 직접 사용할 수 있는 사람입니다. MCP 서버는 AI 도구를 통해 상호작용할 때 그들의 대리인 역할을 합니다. MCP 서버에 맞는 접근 제어 메커니즘을 새로 설계하려면 막대한 노력과 비용이 필요합니다.

이러한 과제에 대한 주요 해결책은 개인 액세스 토큰 (PATs)를 구현하는 것입니다. PATs는 사용자가 자격 증명을 공유하거나 인터랙티브 로그인을 필요로 하지 않고 안전하게 접근할 수 있게 제공합니다.

다음은 이 워크플로우가 작동하는 방식입니다:


이 접근 방식은 기존 서비스가 인증 메커니즘을 유지하면서 MCP 통합을 안전하게 구현할 수 있게 합니다.

건강한 서비스 보안을 유지하면서 AI 도구를 기존 서비스에 연결하는 방법에 대한 블로그 게시물을 참고하거나, 전체 소스 코드 예제를 통해 Logto의 개인 액세스 토큰 (PAT)과 역할 기반 액세스 제어 (RBAC)를 결합하여 MCP가 백엔드 서비스에서 접근할 리소스를 제어하는 방법을 배울 수 있습니다.

요약#
MCP(모델 컨텍스트 프로토콜)는 LLM과 특정 비즈니스의 조합에 혁신적인 변화를 가져옵니다. 그것은 대형 언어 모델의 지식 한계, 전문 도메인 지식의 부족, 외부 데이터 접근에 대한 통일된 표준의 부재 등의 문제를 해결합니다.

자신의 서비스를 MCP에 연결하면 비즈니스에 새로운 가능성을 가져올 것입니다. MCP는 AI와 비즈니스 가치를 연결하는 다리입니다. 회사의 내부 지식을 진정으로 이해하는 AI 어시스턴트를 만들거나, 최신 데이터를 접근하는 지능형 도구를 개발하거나, 산업별 요구 사항을 충족하는 전문 애플리케이션을 구축할 수 있습니다.